{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Workflow:\n",
    "1. Obtaining the pdfs\n",
    "2. Processing the pdf to extract text\n",
    "3. Converting texts into chunks\n",
    "4. Converting chunks into embeddings\n",
    "5. Storing the embeddings in faiss\n",
    "6. Obtaining the user query\n",
    "7. Processing the query and converting into embeddings\n",
    "8. Performing similarity serach in the vectorstore\n",
    "9. Retrieving the results and prompting the LLM with the context and question\n",
    "10. Displaying the result\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracing texts from pdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from PyPDF2 import PdfReader\n",
    "import os\n",
    "\n",
    "\n",
    "def get_pdf_texts(pdf_filepaths):\n",
    "    \"\"\"\n",
    "    Extract text from list of pdf files and retunns a text\n",
    "    \"\"\"\n",
    "    text = \"\"\n",
    "    for filepath in pdf_filepaths:\n",
    "        try:\n",
    "            with open(filepath, 'rb') as pdf_file:  # Open in binary mode for PDFs\n",
    "                reader = PdfReader(pdf_file)\n",
    "                for page in reader.pages:\n",
    "                    page_text = page.extract_text()\n",
    "                    text += page_text\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Error: File '{filepath}' not found. Skipping.\")\n",
    "\n",
    "    # for pdf in pdf_docs:\n",
    "    #     pdf_reader = PdfReader(pdf)\n",
    "    #     for page in pdf_reader.pages:\n",
    "    #         text += page.extract_text()\n",
    "\n",
    "    return text\n",
    "\n",
    "filename = 'pdf1.pdf'\n",
    "\n",
    "pdf_directory = os.getcwd()  # Get current working directory\n",
    "pdf_files = [os.path.join(pdf_directory, filename) for filename in os.listdir(pdf_directory) if filename.endswith('.pdf')]  # Filter for PDF files\n",
    "\n",
    "if pdf_files:\n",
    "  extracted_text = get_pdf_texts(pdf_files)\n",
    "  print(extracted_text)\n",
    "else:\n",
    "  print(\"No PDF files found in the current directory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting texts into chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "def get_text_chunks(text):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size = 5000, chunk_overlap = 2500)\n",
    "    chunks = text_splitter.split_text(text)\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = get_text_chunks(extracted_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting chunks into embeddings Storing the embeddings in faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain_google_genai.embeddings import GoogleGenerativeAIEmbeddings\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import google.generativeai as genai\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv(\"GOOGLE_API\")\n",
    "genai.configure(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vector_store(text_chunks):\n",
    "    embeddings = GoogleGenerativeAIEmbeddings(model = \"models/embedding-001\")\n",
    "    vector_store = FAISS.from_texts(text_chunks, embedding=embeddings)\n",
    "    vector_store.save_local(\"faiss_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_vector_store(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "\n",
    "def get_qa_chain():\n",
    "    template = \"\"\"\n",
    "    Answer the given question according to the context provided. Include the details.\n",
    "    If answer is not in the provided context simply answer \"I dont know the answer\", donot provide wrong answer\n",
    "    \\n\n",
    "    context: {context}\n",
    "    \\n\n",
    "    question: {query}\n",
    "    \\n\n",
    "\n",
    "    Answer: \n",
    "\"\"\"\n",
    "\n",
    "    llm = ChatGoogleGenerativeAI(model=\"gemini-pro\", temperature=0.9, convert_system_message_to_human=True)\n",
    "\n",
    "    prompt = PromptTemplate(template=template, input_variables=['context', 'query'])\n",
    "\n",
    "    chain = load_qa_chain(llm=llm, chain_type='stuff', prompt = prompt)\n",
    "\n",
    "    return chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'output_text': 'I dont know the answer'}\n"
     ]
    }
   ],
   "source": [
    "def get_response(query):\n",
    "    embeddings = GoogleGenerativeAIEmbeddings(model = \"models/embedding-001\")\n",
    "    db = FAISS.load_local(\"faiss_index\", embeddings, allow_dangerous_deserialization= True)\n",
    "    relevant_docs = db.similarity_search(query)\n",
    "\n",
    "    chain = get_qa_chain()\n",
    "\n",
    "    response = chain(\n",
    "        {\n",
    "            \"input_documents\": relevant_docs,\n",
    "            'query': query,\n",
    "        },\n",
    "        return_only_outputs=True\n",
    "    )\n",
    "\n",
    "    print(response)\n",
    "\n",
    "get_response(\"What is the capital of Nepal\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
